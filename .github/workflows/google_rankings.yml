name: Weekly Google Rankings Scraper

on:
  schedule:
    # Schedule to run every Thursday at midnight (UTC)
    - cron: '0 0 * * 4'

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Check out the repository
    - name: Checkout repository
      uses: actions/checkout@v3

    # Step 2: Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        pip install requests

    # Step 4: Run the script
    - name: Run scraper script
      env:
        API_KEY: ${{ secrets.API_KEY }}
        SEARCH_ENGINE_ID: ${{ secrets.SEARCH_ENGINE_ID }}
      run: |
        echo '{"API_KEY": "'${API_KEY}'", "SEARCH_ENGINE_ID": "'${SEARCH_ENGINE_ID}'"}' > config.json
        python test_script.py

    # Step 5: Upload the output CSV file as an artifact (optional)
    - name: Upload output
      uses: actions/upload-artifact@v3
      with:
        name: google_rankings
        path: google_rankings.csv
